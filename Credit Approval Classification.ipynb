{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spread-disability",
   "metadata": {},
   "source": [
    "# Classification Task: Credit Approval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-portugal",
   "metadata": {},
   "source": [
    "### Goal: Create a classifier using the sci-kit learn package\n",
    "\n",
    "We note that this is a fairly balanced dataset where 44% of the target is \"True\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "covered-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-printing",
   "metadata": {},
   "source": [
    "Create Target and replace unknown symbols in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "brazilian-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690 16\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"crx.csv\", header = False, inferSchema = True)\\\n",
    "    .withColumn(\"_c1\", f.col(\"_c1\").cast(DoubleType()))\\\n",
    "    .withColumn(\"_c13\", f.col(\"_c13\").cast(IntegerType()))\\\n",
    "    .withColumn(\"target\", f.when(f.col(\"_c15\") == '+', f.lit(1)).otherwise(f.lit(0)))\\\n",
    "    .drop(\"_c15\")\\\n",
    "    .replace('?', None)\n",
    "total = df.count()\n",
    "print(total, len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-variation",
   "metadata": {},
   "source": [
    "Display percentage of missing values and note continuous vs categorical variables for encoding and imputing in later steps.\n",
    "We will not be using standard scaler or capping variables for this classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "federal-underground",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------------+\n",
      "| _c0|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "|null|   12| 1.7391304347826086|\n",
      "|   b|  468|  67.82608695652173|\n",
      "|   a|  210| 30.434782608695656|\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "| _c1|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "|null|   12| 1.7391304347826086|\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+---+-----+-------------------+\n",
      "|_c2|count|perc_of_count_total|\n",
      "+---+-----+-------------------+\n",
      "+---+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "| _c3|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "|   l|    2| 0.2898550724637681|\n",
      "|null|    6| 0.8695652173913043|\n",
      "|   y|  163|   23.6231884057971|\n",
      "|   u|  519|  75.21739130434783|\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "| _c4|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "|   g|  519|  75.21739130434783|\n",
      "|null|    6| 0.8695652173913043|\n",
      "|   p|  163|   23.6231884057971|\n",
      "|  gg|    2| 0.2898550724637681|\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "| _c5|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "|  cc|   41|  5.942028985507246|\n",
      "|   x|   38|  5.507246376811594|\n",
      "|   m|   38|  5.507246376811594|\n",
      "|null|    9| 1.3043478260869565|\n",
      "|   k|   51|  7.391304347826087|\n",
      "|   e|   25| 3.6231884057971016|\n",
      "|   d|   30| 4.3478260869565215|\n",
      "|   w|   64|   9.27536231884058|\n",
      "|   c|  137| 19.855072463768117|\n",
      "|   i|   59|  8.550724637681158|\n",
      "|  ff|   53|  7.681159420289855|\n",
      "|   q|   78| 11.304347826086957|\n",
      "|   j|   10| 1.4492753623188406|\n",
      "|   r|    3|0.43478260869565216|\n",
      "|  aa|   54|   7.82608695652174|\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "| _c6|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "|null|    9| 1.3043478260869565|\n",
      "|   n|    4| 0.5797101449275363|\n",
      "|   v|  399| 57.826086956521735|\n",
      "|   o|    2| 0.2898550724637681|\n",
      "|   h|  138|               20.0|\n",
      "|  bb|   59|  8.550724637681158|\n",
      "|   z|    8| 1.1594202898550725|\n",
      "|  ff|   57|   8.26086956521739|\n",
      "|   j|    8| 1.1594202898550725|\n",
      "|  dd|    6| 0.8695652173913043|\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+---+-----+-------------------+\n",
      "|_c7|count|perc_of_count_total|\n",
      "+---+-----+-------------------+\n",
      "+---+-----+-------------------+\n",
      "\n",
      "+---+-----+-------------------+\n",
      "|_c8|count|perc_of_count_total|\n",
      "+---+-----+-------------------+\n",
      "|  f|  329|  47.68115942028985|\n",
      "|  t|  361|  52.31884057971015|\n",
      "+---+-----+-------------------+\n",
      "\n",
      "+---+-----+-------------------+\n",
      "|_c9|count|perc_of_count_total|\n",
      "+---+-----+-------------------+\n",
      "|  f|  395|   57.2463768115942|\n",
      "|  t|  295|   42.7536231884058|\n",
      "+---+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "|_c10|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "|_c11|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "|   f|  374|  54.20289855072464|\n",
      "|   t|  316|  45.79710144927536|\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "|_c12|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "|   g|  625|  90.57971014492753|\n",
      "|   p|    8| 1.1594202898550725|\n",
      "|   s|   57|   8.26086956521739|\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "|_c13|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "|null|   13|  1.884057971014493|\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+----+-----+-------------------+\n",
      "|_c14|count|perc_of_count_total|\n",
      "+----+-----+-------------------+\n",
      "+----+-----+-------------------+\n",
      "\n",
      "+------+-----+-------------------+\n",
      "|target|count|perc_of_count_total|\n",
      "+------+-----+-------------------+\n",
      "+------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical = []\n",
    "continuous = []\n",
    "for i, v in enumerate(df.columns):\n",
    "    unique_values = df.groupby(v).count()\\\n",
    "            .withColumn('perc_of_count_total', (f.col('count') / total) * 100)\n",
    "    \n",
    "    if df.dtypes[i][1] == 'string':\n",
    "        categorical.append(v)\n",
    "        \n",
    "        unique_values.show()\n",
    "    else:\n",
    "        continuous.append(v)\n",
    "        unique_values.filter(f.col(v).isNull()).show()\n",
    "continuous.remove(\"target\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-quality",
   "metadata": {},
   "source": [
    "Spark Dataframe to Pandas Dataframe. As this is a small dataset, no sampling is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "specified-crown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c1</th>\n",
       "      <th>_c2</th>\n",
       "      <th>_c7</th>\n",
       "      <th>_c10</th>\n",
       "      <th>_c13</th>\n",
       "      <th>_c14</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>678.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.568171</td>\n",
       "      <td>4.758725</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>184.014771</td>\n",
       "      <td>1017.385507</td>\n",
       "      <td>0.444928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.957862</td>\n",
       "      <td>4.978163</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>173.806768</td>\n",
       "      <td>5210.102598</td>\n",
       "      <td>0.497318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.602500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.460000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.230000</td>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>395.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              _c1         _c2         _c7       _c10         _c13  \\\n",
       "count  678.000000  690.000000  690.000000  690.00000   677.000000   \n",
       "mean    31.568171    4.758725    2.223406    2.40000   184.014771   \n",
       "std     11.957862    4.978163    3.346513    4.86294   173.806768   \n",
       "min     13.750000    0.000000    0.000000    0.00000     0.000000   \n",
       "25%     22.602500    1.000000    0.165000    0.00000    75.000000   \n",
       "50%     28.460000    2.750000    1.000000    0.00000   160.000000   \n",
       "75%     38.230000    7.207500    2.625000    3.00000   276.000000   \n",
       "max     80.250000   28.000000   28.500000   67.00000  2000.000000   \n",
       "\n",
       "                _c14      target  \n",
       "count     690.000000  690.000000  \n",
       "mean     1017.385507    0.444928  \n",
       "std      5210.102598    0.497318  \n",
       "min         0.000000    0.000000  \n",
       "25%         0.000000    0.000000  \n",
       "50%         5.000000    0.000000  \n",
       "75%       395.500000    1.000000  \n",
       "max    100000.000000    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pd = df.toPandas()\n",
    "full_pd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-basement",
   "metadata": {},
   "source": [
    "Impute and encoding variables. For variables with only 2 values, drop a column to reduce redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alert-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    full_pd[col] = full_pd[col].fillna(full_pd.mode()[col][0])\n",
    "for col in continuous:\n",
    "    full_pd[col] = full_pd[col].fillna(full_pd.mean()[col])\n",
    "    \n",
    "dum_pd = pd.get_dummies(full_pd, columns=categorical, prefix=categorical)\n",
    "dum_pd.drop('_c0_b', axis=1, inplace=True)\n",
    "dum_pd.drop('_c11_f', axis=1, inplace=True)\n",
    "dum_pd.drop('_c8_f', axis=1, inplace=True)\n",
    "dum_pd.drop('_c9_f', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-revolution",
   "metadata": {},
   "source": [
    "Train test split, stratify by target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dum_pd.pop('target')\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(dum_pd, y, test_size=0.20, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-administration",
   "metadata": {},
   "source": [
    "Model selection, feature selection, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "disturbed-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.869):\n",
      "{'features__n_features_to_select': 8, 'model__max_depth': 3, 'model__min_samples_split': 50}\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(estimator=RandomForestClassifier())\n",
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('features', rfe),('model', model)])\n",
    "\n",
    "param_grid = {\n",
    "    'features__n_features_to_select':[5, 6, 8],\n",
    "    'model__max_depth': [3, 4, 5],\n",
    "    'model__min_samples_split': [25, 50]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipeline, param_grid, n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-bridge",
   "metadata": {},
   "source": [
    "Create Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "russian-election",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 RFE(estimator=RandomForestClassifier(max_depth=3,\n",
       "                                                      min_samples_split=50),\n",
       "                     n_features_to_select=8)),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(max_depth=3, min_samples_split=50))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(estimator=RandomForestClassifier(max_depth = 3, min_samples_split = 50), n_features_to_select = 8)\n",
    "model = RandomForestClassifier(max_depth = 3, min_samples_split = 50)\n",
    "pipeline = Pipeline(steps=[('features', rfe),('model', model)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-celebrity",
   "metadata": {},
   "source": [
    "Display Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "exclusive-fossil",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_c8_t</th>\n",
       "      <td>0.442669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_c10</th>\n",
       "      <td>0.168993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_c9_t</th>\n",
       "      <td>0.136454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_c7</th>\n",
       "      <td>0.088988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_c14</th>\n",
       "      <td>0.079866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_c2</th>\n",
       "      <td>0.037161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_c13</th>\n",
       "      <td>0.029166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_c1</th>\n",
       "      <td>0.016703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Importance\n",
       "_c8_t    0.442669\n",
       "_c10     0.168993\n",
       "_c9_t    0.136454\n",
       "_c7      0.088988\n",
       "_c14     0.079866\n",
       "_c2      0.037161\n",
       "_c13     0.029166\n",
       "_c1      0.016703"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pipeline.named_steps['model'].feature_importances_,\n",
    "             index = X_train.columns[pipeline.named_steps['features'].ranking_ == 1],\n",
    "             columns = ['Importance']).sort_values(by=['Importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-undergraduate",
   "metadata": {},
   "source": [
    "Display Model Metrics with hold out set to ensure no over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "functioning-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc:  0.9425447685849407\n",
      "holdout auc:  0.9503938684266554\n"
     ]
    }
   ],
   "source": [
    "print ('train auc: ', roc_auc_score(y_train, pipeline.predict_proba(X_train)[:,1]))\n",
    "print ('holdout auc: ', roc_auc_score(y_holdout, pipeline.predict_proba(X_holdout)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-rugby",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
